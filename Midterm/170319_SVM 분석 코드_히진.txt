#SVM 기법 중 kernlab 함수 사용

> letters <- read.csv("C:/Users/CHJ/R_HJ/Machine Learning with R code/mlr-ko/chapter 7/letterdata.csv")

> str(letters)
#str(data) 하면 데이터 구조, 변수명, 변수 개수, 관찰치 개수, 변수별 상위 데이터셋 미리보기 가능
'data.frame':   20000 obs. of  17 variables:
 $ letter: Factor w/ 26 levels "A","B","C","D",..: 20 9 4 14 7 19 2 1 10 13 ...
 $ xbox  : int  2 5 4 7 2 4 4 1 2 11 ...
 $ ybox  : int  8 12 11 11 1 11 2 1 2 15 ...
 $ width : int  3 3 6 6 3 5 5 3 4 13 ...
 $ height: int  5 7 8 6 1 8 4 2 4 9 ...
 $ onpix : int  1 2 6 3 1 3 4 1 2 7 ...
 $ xbar  : int  8 10 10 5 8 8 8 8 10 13 ...
 $ ybar  : int  13 5 6 9 6 8 7 2 6 2 ...
 $ x2bar : int  0 5 2 4 6 6 6 2 2 6 ...
 $ y2bar : int  6 4 6 6 6 9 6 2 6 2 ...
 $ xybar : int  6 13 10 4 6 5 7 8 12 12 ...
 $ x2ybar: int  10 3 3 4 5 6 6 2 4 1 ...
 $ xy2bar: int  8 9 7 10 9 6 6 8 8 9 ...
 $ xedge : int  0 2 3 6 1 0 2 1 1 8 ...
 $ xedgey: int  8 8 7 10 7 8 8 6 6 1 ...
 $ yedge : int  0 4 3 2 5 9 7 2 1 1 ...
 $ yedgex: int  8 10 9 8 10 7 10 7 7 8 ...
#데이터 읽고 각 분류의 속성 수와 문자 26개인 것 확인 가능

> letters_train <- letters[1:16000, ]
> letters_test <- letters[16001:20000, ]
#training과 test 데이터 8:2로 사용

> library(kernlab)
> letter_classifier <- ksvm(letter ~., data=letters_train, kernel="vanilladot")
 Setting default kernel parameters  
##모델 만드는 과정 : m<-ksmv(target~predictors, data=mydata, kernel="rbfdot", C=1)일 때 
target=모델링 하고자 하는 데이터 프레임, predictors=예측에 사용하는 데이터 프레임의 속성 명시한 R공식, data=target과 predictor 변수가 포함돼 있는 데이터 프레임
kernel="rbfdot"(radial basis), "polydot"(polynomial, "tanhdot"(hyperbolic tangentsigmoid), "vanilladot"(linear) 등의 비선형을 명시, C='soft margin'보다 큰 값은 좁은 여백 만듬

> letter_classifier

Support Vector Machine object of class "ksvm" 

SV type: C-svc  (classification) 
 parameter : cost C = 1 

Linear (vanilla) kernel function. 

Number of Support Vectors : 7037 

Objective Function Value : -14.1746 -20.0072 -23.5628 -6.2009 -7.5524 -32.7694 -49.9786 -18.1824 -62.1111 -32.7284 -16.2209 -32.2837 -28.9777 -51.2195 -13.276 -35.6217 -30.8612 -16.5256 -14.6811 -32.7475 -30.3219 -7.7956 -11.8138 -32.3463 -13.1262 -9.2692 -153.1654 -52.9678 -76.7744 -119.2067 -165.4437 -54.6237 -41.9809 -67.2688 -25.1959 -27.6371 -26.4102 -35.5583 -41.2597 -122.164 -187.9178 -222.0856 -21.4765 -10.3752 -56.3684 -12.2277 -49.4899 -9.3372 -19.2092 -11.1776 -100.2186 -29.1397 -238.0516 -77.1985 -8.3339 -4.5308 -139.8534 -80.8854 -20.3642 -13.0245 -82.5151 -14.5032 -26.7509 -18.5713 -23.9511 -27.3034 -53.2731 -11.4773 -5.12 -13.9504 -4.4982 -3.5755 -8.4914 -40.9716 -49.8182 -190.0269 -43.8594 -44.8667 -45.2596 -13.5561 -17.7664 -87.4105 -107.1056 -37.0245 -30.7133 -112.3218 -32.9619 -27.2971 -35.5836 -17.8586 -5.1391 -43.4094 -7.7843 -16.6785 -58.5103 -159.9936 -49.0782 -37.8426 -32.8002 -74.5249 -133.3423 -11.1638 -5.3575 -12.438 -30.9907 -141.6924 -54.2953 -179.0114 -99.8896 -10.288 -15.1553 -3.7815 -67.6123 -7.696 -88.9304 -47.6448 -94.3718 -70.2733 -71.5057 -21.7854 -12.7657 -7.4383 -23.502 -13.1055 -239.9708 -30.4193 -25.2113 -136.2795 -140.9565 -9.8122 -34.4584 -6.3039 -60.8421 -66.5793 -27.2816 -214.3225 -34.7796 -16.7631 -135.7821 -160.6279 -45.2949 -25.1023 -144.9059 -82.2352 -327.7154 -142.0613 -158.8821 -32.2181 -32.8887 -52.9641 -25.4937 -47.9936 -6.8991 -9.7293 -36.436 -70.3907 -187.7611 -46.9371 -89.8103 -143.4213 -624.3645 -119.2204 -145.4435 -327.7748 -33.3255 -64.0607 -145.4831 -116.5903 -36.2977 -66.3762 -44.8248 -7.5088 -217.9246 -12.9699 -30.504 -2.0369 -6.126 -14.4448 -21.6337 -57.3084 -20.6915 -184.3625 -20.1052 -4.1484 -4.5344 -0.828 -121.4411 -7.9486 -58.5604 -21.4878 -13.5476 -5.646 -15.629 -28.9576 -20.5959 -76.7111 -27.0119 -94.7101 -15.1713 -10.0222 -7.6394 -1.5784 -87.6952 -6.2239 -99.3711 -101.0906 -45.6639 -24.0725 -61.7702 -24.1583 -52.2368 -234.3264 -39.9749 -48.8556 -34.1464 -20.9664 -11.4525 -123.0277 -6.4903 -5.1865 -8.8016 -9.4618 -21.7742 -24.2361 -123.3984 -31.4404 -88.3901 -30.0924 -13.8198 -9.2701 -3.0823 -87.9624 -6.3845 -13.968 -65.0702 -105.523 -13.7403 -13.7625 -50.4223 -2.933 -8.4289 -80.3381 -36.4147 -112.7485 -4.1711 -7.8989 -1.2676 -90.8037 -21.4919 -7.2235 -47.9557 -3.383 -20.433 -64.6138 -45.5781 -56.1309 -6.1345 -18.6307 -2.374 -72.2553 -111.1885 -106.7664 -23.1323 -19.3765 -54.9819 -34.2953 -64.4756 -20.4115 -6.689 -4.378 -59.141 -34.2468 -58.1509 -33.8665 -10.6902 -53.1387 -13.7478 -20.1987 -55.0923 -3.8058 -60.0382 -235.4841 -12.6837 -11.7407 -17.3058 -9.7167 -65.8498 -17.1051 -42.8131 -53.1054 -25.0437 -15.302 -44.0749 -16.9582 -62.9773 -5.204 -5.2963 -86.1704 -3.7209 -6.3445 -1.1264 -122.5771 -23.9041 -355.0145 -31.1013 -32.619 -4.9664 -84.1048 -134.5957 -72.8371 -23.9002 -35.3077 -11.7119 -22.2889 -1.8598 -59.2174 -8.8994 -150.742 -1.8533 -1.9711 -9.9676 -0.5207 -26.9229 -30.429 -5.6289 
Training error : 0.130062 
#SVM모델 수행 완료, 얼마나 잘 수행됐는지 알려주지만 테스트 데이터로 성능 살펴볼 필요 있음.

> letter_predictions <- predict(letter_classifier, letters_test)
##예측하기 : p <- predict(m, test, type="response") 일 때 m=ksvm() 함수로 훈련된 모델, test=훈련데이터와 같은 속성을 가진 테스트 데이터를 포함하는 데이터 프레임,
type=예측이 response(예측된 범주)인지 probabilities(예측된 확률, 범주당 하나의 열)인지 명시함. 함수는 type 매개변수에 따라 예측된 범주(또는 확률)의 벡터를 반환함.
#type 매개변수를 명시하지 않으면 기본적으로 response가 사용됨

> head(letter_predictions)
[1] U N V X N H
Levels: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z
#head() 함수 사용해서 상위 6개의 관측치 미리보기 가능 

> table(letter_predictions, letters_test$letter)
letter_predictions   A   B   C   D   E   F   G   H   I   J   K   L   M   N   O   P   Q   R   S   T   U   V   W   X   Y   Z
                 A 144   0   0   0   0   0   0   0   0   1   0   0   1   2   2   0   5   0   1   1   1   0   1   0   0   1
                 B   0 121   0   5   2   0   1   2   0   0   1   0   1   0   0   2   2   3   5   0   0   2   0   1   0   0
                 C   0   0 120   0   4   0  10   2   2   0   1   3   0   0   2   0   0   0   0   0   0   0   0   0   0   0
                 D   2   2   0 156   0   1   3  10   4   3   4   3   0   5   5   3   1   4   0   0   0   0   0   3   3   1
                 E   0   0   5   0 127   3   1   1   0   0   3   4   0   0   0   0   2   0  10   0   0   0   0   2   0   3

#분류기가 얼마나 잘 수행했는지 살펴보기 위해 테스트 데이터셋에서 실제 문자와 예측된 문자를 비교해야 함, 대각선 값인 144, 121 등은 예측과 실제가 일치한 값 나타냄
#잘못된 결과도 나타내줌, B행 D열의 5는 실제 D지만 B로 잘못 예측한 다섯개를 나타내줌

> agreement <- letter_predictions == letters_test$letters
#데이터 프레임 이름$변수명 : 객체를 지정, 어디서 변수를 가져와야 할 지 인식 가능
> table(agreement)
agreement
FALSE  TRUE 
  643  3357 
#모델의 예측값과 실제 값이 일치하는지 true 또는 false로 반환해줌, table() 함수 사용해 4000개 중 3357개 정확하게 식별했음을 알 수 있음
 
> prop.table(table(agreement))
agreement
  FALSE    TRUE 
0.16075 0.83925 
#이를 비율로서 나타내면 정확도는 약 84%이다.

#단순한 선형 커널 함수가 아닌 복잡한 커널 함수 사용해서 SVM 모델 수립해봄, 가우시안 RBF 커널 사용
> letter_classifier_rbf <- ksvm(letter~., data=letters_train, kernel="rbfdot")
> letter_predictions_rbf <- predict(letter_classifier_rbf, letters_test)
> agreement_rbf <- letter_predictions_rbf == letters_test$letter
> table(agreement_rbf)
agreement_rbf
FALSE  TRUE 
  278  3722 
> prop.table(table(agreement_rbf))
agreement_rbf
 FALSE   TRUE 
0.0695 0.9305 
#커널 변경만으로 정확도가 84%에서 93%로 증가, 




#SVM e1071함수 사용
> library(e1071)
> data(iris)
#iris는 Setosa, Versicolor, Virginica 세가지 클래스로 나누어 놓은 데이터
> samp <- c(sample(1:50,25), sample(51:100.25), sample(101:150,25))
> #총 150개 데이터 중 75개 추출해 학습, 나머지 75개는 test 데이터로
> iris.tr <- iris[samp,]
> iris.te <- iris[-samp,]
> model <- svm(Species~., data=iris)
> model

Call:
svm(formula = Species ~ ., data = iris)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  radial 
       cost:  1 
      gamma:  0.25 

Number of Support Vectors:  51
#Species 변수에 대해서 SVM 수행, e1071 라이브러리에서 default kernel 값은 radial임, gamma는 기울기와 비슷
#cost는 과적합을 막는 정도를 지정하는 파라미터. 즉 잘못 분류하면 얼마만큼의 비용을 지불할 것인지 결정하는 것
내가 세운 model이 얼마나 잘 예측했나 table을 통해 비교하면 된다.

> pred <- predict(model, iris[, -5])
> table(pred, iris$Species)
            
pred         setosa versicolor virginica
  setosa         50          0         0
  versicolor      0         48         2
  virginica       0          2        48
#predict라는 함수에서 predic(m, test, type = "response")
#m=Object of class "svm", created by svm.
#test=An object containing the new input data
#type 옵션은 response, probabilities, votes 중 선택할 수 있다.
#response는 default값으로, 반응값이 그대로 반환됨, probabilities는 모델 알고리즘에 따라 확률로 반환된다.
#votes는 각 분류 가능 범주의 순위를 출력한다.

> plot(cmdscale(dist(iris[,-5])), col = as.integer(iris[,5]),pch = c("o","+")[1:150 %in% model$index + 1])
#예측한 model을 plot함수로 그리는데, support vector는 + 모양으로, 아닌 것들은 O로 나타낸다


#------------------------------------------------------------------------------------------------------

> library(e1071)
> data(iris)
> samp <- c(sample(1:50,25), sample(51:100.25), sample(101:150,25))
> iris.tr <- iris[samp,]
> iris.te <- iris[-samp,]
> m1 <- svm(Species~.,data=iris.tr, kernel="linear")
> m2 <- svm(Species~.,data=iris.tr, kernel="polynomial")
> m3 <- svm(Species~.,data=iris.tr, kernel="radial")
> x <- subset(iris.te, select=-Species)
> y <- iris.te$Species
> pred1 <- predict(m1,x)
> pred2 <- predict(m2,x)
> pred3 <- predict(m3,x)
> table(y,pred1)
            pred1
y            setosa versicolor virginica
  setosa         25          0         0
  versicolor      0          0         0
  virginica       0          3        22
> table(y,pred2)
            pred2
y            setosa versicolor virginica
  setosa         25          0         0
  versicolor      0          0         0
  virginica       0          9        16
> table(y,pred3)
            pred3
y            setosa versicolor virginica
  setosa         25          0         0
  versicolor      0          0         0
  virginica       0          3        22

> library(e1071)
> data(iris)
> #data which use analysis
> attach(iris)
> #iris라는 데이터 프레임 계속 사용할 것 
> ##classification mode
> m2 <- svm(Species~., data=iris, kernel="linear")
> plot(m2, iris, Petal.Width~Petal.Length, slice=list(Sepal.Width=3, Sepal.Length=4))
> #SVM한 결과를 표로 나타내줌

#attach(데이터 프레임 이름) : 활성화 시작, detach(데이터 프레임 이름) : 끝, 다수의 R 명령문 입력 시 적합함
-> 공통적으로 계속 사용되는 대상 데이터 프레임을 지정할 때는 attach(), 다른 데이터 프레임으로 바꾸려고 기존 지정 프레임 해제 시는 datach() 사용

 